{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from lxml import etree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseFile(infile, prefix, split_books=False):\n",
    "    '''read xml, write txt'''\n",
    "\n",
    "    doc = etree.parse(infile).getroot()\n",
    "    abbr = doc.find('.//Metadata/Abbr').xpath('string()')\n",
    "\n",
    "    lines = {}\n",
    "    \n",
    "    for l in doc.findall('.//TextUnit'):\n",
    "        loc = l.get('loc')\n",
    "        verse = l.xpath('string()').strip()\n",
    "        \n",
    "        if split_books:\n",
    "            try:\n",
    "                book = int(loc.split('.')[0])\n",
    "            except ValueError:\n",
    "                print(\"Error: Can't parse {} in {}\".format(loc, infile))\n",
    "                continue\n",
    "            suff = '_{:02d}'.format(book)\n",
    "        else:\n",
    "            suff = ''\n",
    "        filename = '{}{}.txt'.format(prefix, suff)\n",
    "\n",
    "        if filename not in lines:\n",
    "            lines[filename] = []\n",
    "        \n",
    "        lines[filename].append('{} {}\\t{}'.format(abbr, loc, verse))\n",
    "\n",
    "    for filename in lines:\n",
    "        print(filename)\n",
    "        with open(filename, 'w') as fh:\n",
    "            for l in lines[filename]:\n",
    "                fh.write(l + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "texts/raw/catullus.carmina.txt\n",
      "texts/raw/lucan.bellum_civile_01.txt\n",
      "texts/raw/lucan.bellum_civile_02.txt\n",
      "texts/raw/lucan.bellum_civile_03.txt\n",
      "texts/raw/lucan.bellum_civile_04.txt\n",
      "texts/raw/lucan.bellum_civile_05.txt\n",
      "texts/raw/lucan.bellum_civile_06.txt\n",
      "texts/raw/lucan.bellum_civile_07.txt\n",
      "texts/raw/lucan.bellum_civile_08.txt\n",
      "texts/raw/lucan.bellum_civile_09.txt\n",
      "texts/raw/lucan.bellum_civile_10.txt\n",
      "texts/raw/ovid.amores_01.txt\n",
      "texts/raw/ovid.amores_02.txt\n",
      "texts/raw/ovid.amores_03.txt\n",
      "texts/raw/ovid.ars_amatoria_01.txt\n",
      "texts/raw/ovid.ars_amatoria_02.txt\n",
      "texts/raw/ovid.ars_amatoria_03.txt\n",
      "texts/raw/ovid.remedia_amoris.txt\n",
      "texts/raw/propertius.elegies_01.txt\n",
      "texts/raw/propertius.elegies_02.txt\n",
      "texts/raw/propertius.elegies_03.txt\n",
      "texts/raw/propertius.elegies_04.txt\n",
      "texts/raw/statius.thebaid_01.txt\n",
      "texts/raw/statius.thebaid_02.txt\n",
      "texts/raw/statius.thebaid_03.txt\n",
      "texts/raw/statius.thebaid_04.txt\n",
      "texts/raw/statius.thebaid_05.txt\n",
      "texts/raw/statius.thebaid_06.txt\n",
      "texts/raw/statius.thebaid_07.txt\n",
      "texts/raw/statius.thebaid_08.txt\n",
      "texts/raw/statius.thebaid_09.txt\n",
      "texts/raw/statius.thebaid_10.txt\n",
      "texts/raw/statius.thebaid_11.txt\n",
      "texts/raw/statius.thebaid_12.txt\n",
      "Error: Can't parse Marsi.1 in texts/xml/tibullus.elegies.xml\n",
      "Error: Can't parse Marsi.2 in texts/xml/tibullus.elegies.xml\n",
      "Error: Can't parse Marsi.3 in texts/xml/tibullus.elegies.xml\n",
      "Error: Can't parse Marsi.4 in texts/xml/tibullus.elegies.xml\n",
      "texts/raw/tibullus.elegies_01.txt\n",
      "texts/raw/tibullus.elegies_02.txt\n",
      "texts/raw/tibullus.elegies_03.txt\n",
      "texts/raw/valerius_flaccus.argonautica_01.txt\n",
      "texts/raw/valerius_flaccus.argonautica_02.txt\n",
      "texts/raw/valerius_flaccus.argonautica_03.txt\n",
      "texts/raw/valerius_flaccus.argonautica_04.txt\n",
      "texts/raw/valerius_flaccus.argonautica_05.txt\n",
      "texts/raw/valerius_flaccus.argonautica_06.txt\n",
      "texts/raw/valerius_flaccus.argonautica_07.txt\n",
      "texts/raw/valerius_flaccus.argonautica_08.txt\n",
      "texts/raw/vergil.aeneid_01.txt\n",
      "texts/raw/vergil.aeneid_02.txt\n",
      "texts/raw/vergil.aeneid_03.txt\n",
      "texts/raw/vergil.aeneid_04.txt\n",
      "texts/raw/vergil.aeneid_05.txt\n",
      "texts/raw/vergil.aeneid_06.txt\n",
      "texts/raw/vergil.aeneid_07.txt\n",
      "texts/raw/vergil.aeneid_08.txt\n",
      "texts/raw/vergil.aeneid_09.txt\n",
      "texts/raw/vergil.aeneid_10.txt\n",
      "texts/raw/vergil.aeneid_11.txt\n",
      "texts/raw/vergil.aeneid_12.txt\n"
     ]
    }
   ],
   "source": [
    "files = [\n",
    "    ('catullus.carmina', False),\n",
    "    ('lucan.bellum_civile', True),\n",
    "    ('ovid.amores', True),\n",
    "    ('ovid.ars_amatoria', True),\n",
    "    ('ovid.remedia_amoris', False),\n",
    "    ('propertius.elegies', True),\n",
    "    ('statius.thebaid', True),\n",
    "    ('tibullus.elegies', True),\n",
    "    ('valerius_flaccus.argonautica', True),\n",
    "    ('vergil.aeneid', True),\n",
    "]\n",
    "\n",
    "for file, split_books in files:\n",
    "    infile = os.path.join('texts', 'xml', file + '.xml')\n",
    "    outfile = os.path.join('texts', 'raw', file)\n",
    "    parseFile(infile, outfile, split_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download texts from Perseus\n",
    "from lxml import etree\n",
    "import re\n",
    "from MyCapytain.resolvers.cts.api import HttpCtsResolver\n",
    "from MyCapytain.retrievers.cts5 import HttpCtsRetriever\n",
    "\n",
    "SERVER = 'http://cts.perseids.org/api/cts/'\n",
    "resolver = HttpCtsResolver(HttpCtsRetriever(SERVER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieveXML(resolver, urn):\n",
    "    '''Download a remote work and extract xml'''\n",
    "\n",
    "    print('Downloading {}'.format(urn))\n",
    "        \n",
    "    # get references \n",
    "    reffs = resolver.getReffs(urn)\n",
    "    \n",
    "    # stores parsed xml\n",
    "    xml_reffs = []\n",
    "\n",
    "    # download one book at a time\n",
    "    for i, reff in enumerate(reffs):\n",
    "\n",
    "        print(\" - fetching reff {}/{}\".format(i+1, len(reffs)))\n",
    "        ctsPassage = resolver.getTextualNode(urn, subreference=reff)\n",
    "\n",
    "        # extract xml\n",
    "        xml = ctsPassage.export('python/lxml')\n",
    "        xml_reffs.append(xml)\n",
    "    \n",
    "    return xml_reffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catullus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# catullus\n",
    "catul = retrieveXML(resolver, 'urn:cts:latinLit:phi0472.phi001.perseus-eng4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading urn:cts:latinLit:phi0472.phi001.perseus-eng4\n",
      " - fetching reff 1/120\n",
      " - fetching reff 2/120\n",
      " - fetching reff 3/120\n",
      " - fetching reff 4/120\n",
      " - fetching reff 5/120\n",
      " - fetching reff 6/120\n",
      " - fetching reff 7/120\n",
      " - fetching reff 8/120\n",
      " - fetching reff 9/120\n",
      " - fetching reff 10/120\n",
      " - fetching reff 11/120\n",
      " - fetching reff 12/120\n",
      " - fetching reff 13/120\n",
      " - fetching reff 14/120\n",
      " - fetching reff 15/120\n",
      " - fetching reff 16/120\n",
      " - fetching reff 17/120\n",
      " - fetching reff 18/120\n",
      " - fetching reff 19/120\n",
      " - fetching reff 20/120\n",
      " - fetching reff 21/120\n",
      " - fetching reff 22/120\n",
      " - fetching reff 23/120\n",
      " - fetching reff 24/120\n",
      " - fetching reff 25/120\n",
      " - fetching reff 26/120\n",
      " - fetching reff 27/120\n",
      " - fetching reff 28/120\n",
      " - fetching reff 29/120\n",
      " - fetching reff 30/120\n",
      " - fetching reff 31/120\n",
      " - fetching reff 32/120\n",
      " - fetching reff 33/120\n",
      " - fetching reff 34/120\n",
      " - fetching reff 35/120\n",
      " - fetching reff 36/120\n",
      " - fetching reff 37/120\n",
      " - fetching reff 38/120\n",
      " - fetching reff 39/120\n",
      " - fetching reff 40/120\n",
      " - fetching reff 41/120\n",
      " - fetching reff 42/120\n",
      " - fetching reff 43/120\n",
      " - fetching reff 44/120\n",
      " - fetching reff 45/120\n",
      " - fetching reff 46/120\n",
      " - fetching reff 47/120\n",
      " - fetching reff 48/120\n",
      " - fetching reff 49/120\n",
      " - fetching reff 50/120\n",
      " - fetching reff 51/120\n",
      " - fetching reff 52/120\n",
      " - fetching reff 53/120\n",
      " - fetching reff 54/120\n",
      " - fetching reff 55/120\n",
      " - fetching reff 56/120\n",
      " - fetching reff 57/120\n",
      " - fetching reff 58/120\n",
      " - fetching reff 59/120\n",
      " - fetching reff 60/120\n",
      " - fetching reff 61/120\n",
      " - fetching reff 62/120\n",
      " - fetching reff 63/120\n",
      " - fetching reff 64/120\n",
      " - fetching reff 65/120\n",
      " - fetching reff 66/120\n",
      " - fetching reff 67/120\n",
      " - fetching reff 68/120\n",
      " - fetching reff 69/120\n",
      " - fetching reff 70/120\n",
      " - fetching reff 71/120\n",
      " - fetching reff 72/120\n",
      " - fetching reff 73/120\n",
      " - fetching reff 74/120\n",
      " - fetching reff 75/120\n",
      " - fetching reff 76/120\n",
      " - fetching reff 77/120\n",
      " - fetching reff 78/120\n",
      " - fetching reff 79/120\n",
      " - fetching reff 80/120\n",
      " - fetching reff 81/120\n",
      " - fetching reff 82/120\n",
      " - fetching reff 83/120\n",
      " - fetching reff 84/120\n",
      " - fetching reff 85/120\n",
      " - fetching reff 86/120\n",
      " - fetching reff 87/120\n",
      " - fetching reff 88/120\n",
      " - fetching reff 89/120\n",
      " - fetching reff 90/120\n",
      " - fetching reff 91/120\n",
      " - fetching reff 92/120\n",
      " - fetching reff 93/120\n",
      " - fetching reff 94/120\n",
      " - fetching reff 95/120\n",
      " - fetching reff 96/120\n",
      " - fetching reff 97/120\n",
      " - fetching reff 98/120\n",
      " - fetching reff 99/120\n",
      " - fetching reff 100/120\n",
      " - fetching reff 101/120\n",
      " - fetching reff 102/120\n",
      " - fetching reff 103/120\n",
      " - fetching reff 104/120\n",
      " - fetching reff 105/120\n",
      " - fetching reff 106/120\n",
      " - fetching reff 107/120\n",
      " - fetching reff 108/120\n",
      " - fetching reff 109/120\n",
      " - fetching reff 110/120\n",
      " - fetching reff 111/120\n",
      " - fetching reff 112/120\n",
      " - fetching reff 113/120\n",
      " - fetching reff 114/120\n",
      " - fetching reff 115/120\n",
      " - fetching reff 116/120\n",
      " - fetching reff 117/120\n",
      " - fetching reff 118/120\n",
      " - fetching reff 119/120\n",
      " - fetching reff 120/120\n"
     ]
    }
   ],
   "source": [
    "# process all individual poems of Catullus\n",
    "# and paste them together into a single text\n",
    "\n",
    "dest = os.path.join('catullus.elegiacs.txt')\n",
    "\n",
    "poems = []\n",
    "\n",
    "for doc in catul[66:]:\n",
    "    div = doc.find('.//{http://www.tei-c.org/ns/1.0}div[@subtype=\"textpart\"]')\n",
    "    paras = div.findall('.//{http://www.tei-c.org/ns/1.0}p')\n",
    "    if len(paras) > 1:\n",
    "        for p in paras:\n",
    "            if p.tail:\n",
    "                p.tail = '==PARA==' + p.tail\n",
    "            else:\n",
    "                p.tail = '==PARA=='\n",
    "\n",
    "    # remove speaker indications from dialogue\n",
    "    for speaker in div.findall('.//{http://www.tei-c.org/ns/1.0}speaker'):\n",
    "        speaker.clear()\n",
    "\n",
    "    poem = div.xpath('string()')\n",
    "    poem = re.sub(pattern='\\s+', repl=' ', string=poem)\n",
    "    poem = re.sub(pattern='(==PARA==)+', repl='\\n\\n    ', string=poem)\n",
    "    poem = poem.strip()\n",
    "    poem = re.sub(pattern='[—]', repl=' – ', string=poem)\n",
    "    poems.append(poem)\n",
    "\n",
    "with open(dest, 'w') as fh:\n",
    "    fh.write('\\n\\n---\\n\\n'.join(poems))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/chris/Documents/git/clas-3991-fa18/Week 02 - Flow Control and Functions'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *  *\n",
    "## Cut from the lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3D PCA plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'numpy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-03fcd34277ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# leave out lucan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0msome_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lucan'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# build feature vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'numpy' is not defined"
     ]
    }
   ],
   "source": [
    "%matplotlib notebook\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from sklearn import decomposition\n",
    "\n",
    "# leave out lucan\n",
    "some_files = numpy.array([f for f in files if not f.startswith('lucan')])\n",
    "\n",
    "# build feature vectors\n",
    "data = []\n",
    "\n",
    "for file in some_files:\n",
    "    path = os.path.join('texts', 'raw', file)\n",
    "    wc = wordCount(path)\n",
    "\n",
    "    this_vec = [wc.get(w, 0) for w in top_500]\n",
    "    data.append(this_vec)\n",
    "    \n",
    "data = numpy.array(data)\n",
    "\n",
    "# create author labels\n",
    "authors = []\n",
    "for f in some_files:\n",
    "    author = f.split('.')[0]\n",
    "    authors.append(author)\n",
    "\n",
    "# reduce dimensionality with PCA\n",
    "npcs = 10\n",
    "print('Calculating {} principal components'.format(npcs))\n",
    "pcmodel = decomposition.PCA(npcs)\n",
    "pca = pcmodel.fit_transform(data)\n",
    "\n",
    "# create a graph\n",
    "fig = pyplot.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.set_xlabel('PC1')\n",
    "ax.set_ylabel('PC2')\n",
    "ax.set_zlabel('PC3')\n",
    "\n",
    "# use numpy for easier array slicing\n",
    "x = pca[:,0]\n",
    "y = pca[:,1]\n",
    "z = pca[:,2]\n",
    "g = numpy.array(genres)\n",
    "a = numpy.array(authors)\n",
    "\n",
    "# plot each author as a separate series\n",
    "for auth in set(a):\n",
    "    ax.scatter(x[a==auth], y[a==auth], z[a==auth], marker='o', label=auth)\n",
    "    \n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
