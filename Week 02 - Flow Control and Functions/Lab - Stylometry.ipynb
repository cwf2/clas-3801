{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Love and War: Stylometry in Latin Poetry\n",
    "\n",
    "In this lab, we're going to use word counts to look at the difference between two genres of Latin poetry, Epic and Elegy.\n",
    "<div class=\"alert alert-info\" style=\"margin:2em;\">\n",
    "<h5>Epic</h5>\n",
    "<ul>\n",
    "    <li>Treats grand events from mythology and history: e.g., the Trojan War, Jason and the Argonauts, the founding of Rome.</li>\n",
    "    <li>Long poems (10,000 lines or more), divided into chapter-like \"books.\"</li>\n",
    "    <li>Written as a continous series of hexameter lines.</li>\n",
    "    <li>Elevated style and diction.</li>\n",
    "</ul>\n",
    "</div>\n",
    "<div class=\"alert alert-info\" style=\"margin: 2em;\">\n",
    "<h5>Elegy</h5>\n",
    "<ul>\n",
    "    <li>Treats personal issues‚Äîespecially love, but also friendships and grudges.</li>\n",
    "    <li>Shorter poems (tens to hundreds of lines), arranged loosely in groups.</li>\n",
    "    <li>Lines are grouped in couplets: one hexameter and one pentameter.</li>\n",
    "    <li>Diction is often lower‚Äîincludes conversational and vulgar language.</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The corpus\n",
    "\n",
    "These are the texts I've chosen to represent each genre:\n",
    "\n",
    "#### Epics\n",
    "\n",
    "<table class=\"table table-striped\">\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>Author</th>\n",
    "            <th>Title</th>\n",
    "            <th>Date</th>\n",
    "            <th>Lines</th>\n",
    "            <th>Divided into</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>Vergil</td>\n",
    "            <td><em>Aeneid</em></td>\n",
    "            <td>19 BCE</td>\n",
    "            <td>9896</td>\n",
    "            <td>12 Books</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Lucan</td>\n",
    "            <td><em>Civil War</em></td>\n",
    "            <td>65 CE</td>\n",
    "            <td>8061</td>\n",
    "            <td>10 Books</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Statius</td>\n",
    "            <td><em>Thebaid</em></td>\n",
    "            <td>90s CE</td>\n",
    "            <td>9731</td>\n",
    "            <td>12 Books</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Valerius Flaccus</td>\n",
    "            <td><em>Argonautica</em></td>\n",
    "            <td>90s CE</td>\n",
    "            <td>5592</td>\n",
    "            <td>8 Books</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>\n",
    "\n",
    "#### Elegies\n",
    "\n",
    "<table class=\"table table-striped\">\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>Author</th>\n",
    "            <th>Title</th>\n",
    "            <th>Date</th>\n",
    "            <th>Lines</th>\n",
    "            <th>Divided into</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td>Catullus</td>\n",
    "            <td>Poems 65‚Äì116</td>\n",
    "            <td>50s BCE</td>\n",
    "            <td>643</td>\n",
    "            <td>‚Äî</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Tibullus</td>\n",
    "            <td><em>Elegies</em> (Books 1 and 2)</td>\n",
    "            <td>30‚Äì20 BCE</td>\n",
    "            <td>1241</td>\n",
    "            <td>2 Books</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Propertius</td>\n",
    "            <td><em>Elegies</em></td>\n",
    "            <td>20s‚Äì10s BCE</td>\n",
    "            <td>3982</td>\n",
    "            <td>4 Books</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Ovid</td>\n",
    "            <td><em>Amores</em></td>\n",
    "            <td>10s (?) BCE</td>\n",
    "            <td>2458</td>\n",
    "            <td>3 Books</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td>Pseudo-Tibullus (perhaps several authors)</td>\n",
    "            <td>Transmitted with Tibullus as <em>Elegies</em> Book 3</td>\n",
    "            <td>1st century CE (??)</td>\n",
    "            <td>684</td>\n",
    "            <td>‚Äî</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data and sources\n",
    "\n",
    "The texts we're using today were all drawn from online, public-domain or open-source editions. \n",
    "\n",
    "The Latin texts I occasionally refer to are all from the [Perseus Digital Library](http://www.perseus.tufts.edu/hopper/); Perseus in turn digitized and hand-corrected them from out-of-copyright editions of the late 19th and early 20th centuries. You can browse Perseus' library [here](http://scaife.perseus.org/), or download their entire Latin collection in (XML format) [here](https://github.com/PerseusDL/canonical-latinLit).\n",
    "\n",
    "**The English texts** we'll use for most of the lab are from a couple of places, but all essentially go back to out-of-copyright volumes from the [Loeb Classical Library](https://www.loebclassics.com/page/history). Catullus is from Perseus. Most of the epic authors are from the [Theoi Texts Library](http://theoi.com/Library.html). The rest I got by searching for specific Loebs at the [Internet Archive](https://archive.org/).\n",
    "\n",
    "I've modified all of these texts to make them easier for us to use. Depending on the source, digital texts can be easy to work with or very difficult; Perseus' texts are formatted so that you can download and manipulate them easily using scripts; the Internet Archive texts, on the other hand, are just raw text‚Äîoften uncorrected OCR, which means they have lots weird \"typos.\"\n",
    "\n",
    "You can browse the texts using Jupyter's dashboard. Click on the `texts` folder, and then the `latin` or `english` subfolder, and then pick a text to examine. If you have trouble finding the files, just let me know and I can help out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<h5>‚úèÔ∏è Analysis</h5>\n",
    "<p>Before moving on, take a moment with your group to **look at the data summary** above. Then **skim through one or two of the text files.**</p>\n",
    "<ul>\n",
    "    <li>Do you notice any patterns, trends, or systematic differences between the groups?</li>\n",
    "    <li>Do any of the texts stand out as anomalous?</li>\n",
    "    <li>Does anyone in your group know something interesting about these authors or works?</li>\n",
    "    <li>Can you suggest any possible sources of bias we might want to watch out for?</li>\n",
    "</ul>\n",
    "<p>Spend a few minutes talking it over, then **write a brief response** in the cell below.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries\n",
    "\n",
    "For this lab, I've written a lot of the code we'll need ahead of time. Please run the following cell to get started. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dealing with files and directories\n",
    "import os\n",
    "\n",
    "# for string processing\n",
    "import re\n",
    "\n",
    "# for dictionary-like counters\n",
    "from collections import Counter\n",
    "\n",
    "# for graphing\n",
    "import numpy\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the directory\n",
    "\n",
    "The following code snippet reads the contents `texts/english` directory.\n",
    "   - files ending with `.txt` are saved to a list called `files`\n",
    "\n",
    "<div class=\"alert alert-info\" style=\"margin:0.5em 2em;\">\n",
    "üëâüèª If you want to try processing the Latin files later, just change `english` to `latin` and re-run this code.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a folder to work with\n",
    "folder = os.path.join('texts', 'english')\n",
    "\n",
    "# create a list of files\n",
    "files = []\n",
    "for f in os.listdir(folder):\n",
    "    if f.endswith('.txt'):\n",
    "        files.append(f)\n",
    "\n",
    "# reorder the list alphabetically\n",
    "files.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a list of genre labels\n",
    "\n",
    "To help keep our data organized, it's useful to have another list, *in the same order*, that gives the genre for each of the files. The code below assigns each file to a genre based on the author's name, which is built into the file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with an empty list\n",
    "genres = []\n",
    "\n",
    "for file in files:\n",
    "    \n",
    "    # author is first element of filename\n",
    "    auth = file.split('.')[0]\n",
    "    \n",
    "    # assign genre\n",
    "    if auth in ['lucan', 'statius', 'valerius_flaccus', 'vergil']:\n",
    "        genre = 'epic'\n",
    "    else:\n",
    "        genre = 'elegy'\n",
    "        \n",
    "    # add genre to list\n",
    "    genres.append(genre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<h5>‚úèÔ∏è Double check</h5>\n",
    "<p>\n",
    "Before moving on, check the contents of the two lists against the names of the files in the `texts/english` folder.\n",
    "</p>\n",
    "<ul>\n",
    "    <li>In the cell below, **write a `for` loop** to print out the items of `files` and `genres`.</li>\n",
    "</ul>\n",
    "<p><strong>Hint:</strong> Begin like this...</p>\n",
    "<pre>\n",
    "for file, genre in zip(files, genres):\n",
    "</pre>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: Counting words\n",
    "\n",
    "The following code defines a new function, `wordCount()`:\n",
    "  - it takes a file as its argument\n",
    "  - it returns a dictionary (actually, a dictionary-like object called a [*Counter*](https://docs.python.org/3.6/library/collections.html#counter-objects)).\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<strong>Dictionaries</strong> are containers that store multiple <strong>values</strong>. Each value is accessed using a unique <strong>key</strong>. In this case, the values are counts, and the keys are the words to be counted. You access the count for a given word by passing that word as a key to the dictionary.\n",
    "</div>\n",
    "\n",
    "Run the cell below, then proceed with the example that follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordCount(path, normalize=False):\n",
    "    '''Read a text file and produce a set of word counts as a Counter.'''\n",
    "    \n",
    "    # a dictionary to collect the word counts\n",
    "    wc = Counter()\n",
    "    \n",
    "    # open the file\n",
    "    file = open(path)\n",
    "    \n",
    "    # process each line in turn:\n",
    "    #  - cut off the line number tags\n",
    "    #  - make the line lowercase\n",
    "    #  - remove all non-letter characters\n",
    "    #  - break into words\n",
    "    #  - make sure there are no empty strings\n",
    "    \n",
    "    for line in file:\n",
    "\n",
    "        # remove locus tags if present (only in latin)\n",
    "        if '\\t' in line:\n",
    "            text = line.split('\\t')[-1]\n",
    "        else:\n",
    "            text = line\n",
    "        \n",
    "        # lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # scrub non-letter chars\n",
    "        text = re.sub(pattern='[^a-z ]', repl='', string=text)\n",
    "        \n",
    "        # split into words\n",
    "        words = text.strip().split()\n",
    "        \n",
    "        # add words to counter\n",
    "        wc.update(words)\n",
    "          \n",
    "    # optional normalization to freq per thousand words\n",
    "    if normalize:\n",
    "        total = sum(wc.values())\n",
    "        for word in wc:\n",
    "            wc[word] = round(1000 * wc[word] / total, 2)\n",
    "\n",
    "    return wc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example\n",
    "\n",
    "```python\n",
    "# pick a file to examine; must include the enclosing folder\n",
    "file = os.path.join(folder, 'lucan.civil_war_07.txt')\n",
    "\n",
    "# call the function and assign the result to a variable\n",
    "wc = wordCount(file)\n",
    "\n",
    "# check a specific word count\n",
    "print(wc['caesar'])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<h5>‚úèÔ∏è Try it out</h5>\n",
    "<p>\n",
    "Test the function on book 1 of Vergil's *Aeneid*. How many times does this book refer to . . .\n",
    "</p>\n",
    "<ul>\n",
    "    <li>Aeneas</li>\n",
    "    <li>Dido</li>\n",
    "    <li>Troy</li>\n",
    "    <li>Rome</li>\n",
    "</ul> \n",
    "<p><strong>Show your code</strong> in the cell below. Remember to use square brackets around the word you want to look up.</p>\n",
    "<p>ü§î Can you use a loop to check all these words?</p>\n",
    "<p>ü§î If you find you're getting the hang of it, then try some other words, or maybe a different book for comparison.</p> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: A toy model of genre\n",
    "\n",
    "Let's start with a comparison of word counts for a couple of important thematic words for these genres: \"arms\" (Latin *arma*) and \"love\" (Latin *amor*).\n",
    "\n",
    "<div class=\"alert alert-info\" style=\"margin: 0.5em 2em;\">\n",
    "<p><strong><em>arma</em></strong>, famously the first word of Vergil's *Aeneid*, is a key word for epic. Its meaning takes in both weapons and armour: swords and spears used for attack, but also the divine shield made for Aeneas. It's not completly absent from elegy, though. A common elegiac trope compares the lover to a soldier on campaign; and Ovid uses the word to open his *Amores* as a kind of literary joke on Vergil.</p>\n",
    "<p><strong><em>amor</em></strong> means \"love,\" either in the abstract or personified as Cupid. In the plural it means \"love affairs.\" Obviously a principal theme of elegy, it also has an important place in epic: think of the affairs of Aeneas and Dido, Jason and Medea, among others.</p>\n",
    "</div>\n",
    "\n",
    "### Tallying\n",
    "\n",
    "In the code below, `wordCount()` is called on each of the files in turn. A summary table is produced comparing counts for 'arms' and 'love', listed alongside the file and genre labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over file and genre tags together\n",
    "for file, genre in zip(files, genres):\n",
    "    \n",
    "    # get file path and call wordCount\n",
    "    path = os.path.join(folder, file)\n",
    "    wc = wordCount(path)\n",
    "    \n",
    "    # check \n",
    "    arms = wc.get('arms', 0)\n",
    "    love = wc.get('love', 0)\n",
    "\n",
    "    print('\\t'.join([genre, str(arms), str(love), file]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<h5>‚úèÔ∏è Analysis</h5>\n",
    "<p>Before moving on, take a moment with your group to **look at the data** above.</p>\n",
    "<ul>\n",
    "    <li>What range of values does the 'love' tally cover? What about 'arms'?</li>\n",
    "    <li>Is there a noticeable difference between the genres?</li>\n",
    "    <li>What kind of variation exists *within* a given text, (i.e. from book to book)? Do single books stand out?</li>\n",
    "    <li>Is there a more useful way to organize this data?</li>\n",
    "</ul>\n",
    "<p>Spend a few minutes talking it over, then **write a brief response** in the cell below.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "\n",
    "One issue that I expect will have come up in our discussions is that the books are of different lengths. Raw word counts are therefore not as meaningful as word use **rates**. A common measure of word frequency is **count per thousand words**. The process of turning observed counts into frequencies like this is called **normalization**.\n",
    "\n",
    "I've already built an **optional parameter** called `normalize` into the `wordCount()` function. By default, it's set to `False`; to use it, you have to manually pass a value of `True` when you call the function.\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "wc = wordCount('texts/english/vergil.aeneid_01.txt', normalize=True)\n",
    "```\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<h5>‚úèÔ∏è You try it</h5>\n",
    "\n",
    "<p>Redo the table above with normalized values.</p>\n",
    "<ul>\n",
    "    <li>Copy-paste the previous code block to the cell below.</li>\n",
    "    <li>Modify the call to `wordCount()` so that results are normalized</li>\n",
    "</ul>    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<h5>‚úèÔ∏è Analysis</h5>\n",
    "<p>Very briefly, use the cell below to respond:</p>\n",
    "<ul>\n",
    "    <li>What are the new ranges like?</li>\n",
    "    <li>Are the normalized values harder to read, or easier?</li>\n",
    "    <li>Does the broad epic/elegy relationship still hold?</li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting\n",
    "\n",
    "As you likely guessed, the next step is to plot the values; often we notice things visually that might be difficult to pick out from the numbers. The code below defines a new function, `plotWords()`:\n",
    "\n",
    " - arguments are two strings: `x_word` and `y_word`\n",
    " - the function plots all the files on a graph, using the frequencies of these two words\n",
    " - add an optional `normalize=True` to plot freq / 1000 words instead of raw counts\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "plotWords('arms', 'love')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "%matplotlib inline\n",
    "import numpy\n",
    "\n",
    "#\n",
    "# define custom plotting function\n",
    "#\n",
    "\n",
    "def plotWords(x_word, y_word, normalize=False):\n",
    "    '''Count frequencies of given words and draw a graph'''\n",
    "\n",
    "    # create a graph\n",
    "    fig = pyplot.figure(figsize=(8,5))\n",
    "    ax = fig.add_axes([.1, .1, .8, .8])\n",
    "    ax.set_xlabel(x_word)\n",
    "    ax.set_ylabel(y_word)\n",
    "\n",
    "    # collect word counts\n",
    "    x_vals = []\n",
    "    y_vals = []\n",
    "\n",
    "    for file in files:\n",
    "        path = os.path.join(folder, file)\n",
    "        wc = wordCount(path, normalize=normalize)\n",
    "\n",
    "        x_vals.append(wc.get(x_word, 0))\n",
    "        y_vals.append(wc.get(y_word, 0))\n",
    "\n",
    "    # use numpy for easier array slicing\n",
    "    x = numpy.array(x_vals)\n",
    "    y = numpy.array(y_vals)\n",
    "    g = numpy.array(genres)\n",
    "\n",
    "    # plot epic and elegy as two series\n",
    "    ax.plot(x[g=='epic'], y[g=='epic'], marker='o', linestyle='', label='epic')\n",
    "    ax.plot(x[g=='elegy'], y[g=='elegy'], marker='o', linestyle='', label='elegy')\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<h5>‚úèÔ∏è You try it</h5>\n",
    "\n",
    "<p>Run the function to plot `arms` versus `love` for all the files. Compare the raw and normalized results.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<h5>‚úèÔ∏è Analysis</h5>\n",
    "\n",
    "<p>With your group, take a few minutes to look at the plots and discuss.</p>\n",
    "<ul>\n",
    "    <li>What patterns are apparent?</li>\n",
    "    <li>Can you suggest a simple rule for predicting the genre of a work? How many would it get right?</li>\n",
    "    <li>Are both word counts equally useful in distinguishing epic and elegy?</li>\n",
    "    <li>Are there outliers among the texts? Can you figure out which they are?</li>\n",
    "</ul>\n",
    "\n",
    "<p>Respond briefly in the cell below.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III: Expanding the model\n",
    "\n",
    "Having seen what we can do with the toy model, let's broaden our approach to consider other words. First, we'll get an overview of the lexicon for the entire corpus, but creating one master word count. Run the code below to get started."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new count for the whole corpus\n",
    "wc_total = Counter()\n",
    "\n",
    "# add up individual counts\n",
    "for file in files:\n",
    "    path = os.path.join(folder, file)\n",
    "    wc_total.update(wordCount(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the frequencies of individual words, as you did above. You can also get the top <var>N</var> words in descending order with a special Counter method called `.most_common()`.\n",
    "\n",
    "**Example:**\n",
    "```python\n",
    "wc_total.most_common(25)\n",
    "```\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<h4>Try it out</h4>\n",
    "<p>ü§î Investigate the most common words in our corpus.</p>\n",
    "<p>ü§î Try using plotWords() to explore other word pairs.</p>\n",
    "<p>Then proceed to the analysis questions below.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<h5>‚úèÔ∏è Analysis</h5>\n",
    "<ul>\n",
    "    <li>Do you see an approximate division by frequency into function / content words?</li>\n",
    "    <li>Among the content words, which seem most prominent?</li>\n",
    "    <li>Do function/content words behave differently in `plotWords()`?</li>\n",
    "    <li>What words in particular get the best separation between the genres?</li>\n",
    "    </ul>\n",
    "    <p>Respond briefly in the cell below.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: Principal Components Analysis\n",
    "\n",
    "<p>In the Hildegard study, the authors used Principal Components Analysis to distil a large number of word frequencies down to <var>x</var> and <var>y</var> parameters for their graphs.</p>\n",
    "\n",
    "<p>The code below will do the same for our own corpus. It defines a new function, `plotPCA()`, which takes an optional parameter `n`, the number of word frequencies to use. By default, `n` is 500.</p>\n",
    "\n",
    "**Example**:\n",
    "\n",
    "```python\n",
    "# with default n\n",
    "plotPCA()\n",
    "\n",
    "# with custom n\n",
    "plotPCA(250)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from sklearn import decomposition\n",
    "\n",
    "def plotPCA(n=500):\n",
    "    '''Create PCA chart from top n word frequencies'''\n",
    "\n",
    "    features = [w for w, c in wc_total.most_common(n)]\n",
    "\n",
    "    # build feature vectors\n",
    "    data = []\n",
    "\n",
    "    for file in files:\n",
    "        path = os.path.join(folder, file)\n",
    "        wc = wordCount(path, True)\n",
    "\n",
    "        this_vec = [wc.get(w, 0) for w in features]\n",
    "        data.append(this_vec)\n",
    "\n",
    "    data = numpy.array(data)\n",
    "\n",
    "    # create author labels\n",
    "    authors = []\n",
    "    for f in files:\n",
    "        author = f.split('.')[0]\n",
    "        authors.append(author)\n",
    "\n",
    "    # reduce dimensionality with PCA\n",
    "    npcs = 2\n",
    "    pcmodel = decomposition.PCA(npcs)\n",
    "    pca = pcmodel.fit_transform(data)\n",
    "\n",
    "    # create a graph\n",
    "    fig, ax = pyplot.subplots()\n",
    "    ax.set_xlabel('PC1')\n",
    "    ax.set_ylabel('PC2')\n",
    "    ax.set_title('Top {} words'.format(n))\n",
    "\n",
    "    # use numpy for easier array slicing\n",
    "    x = pca[:,0]\n",
    "    y = pca[:,1]\n",
    "    a = numpy.array(authors)\n",
    "\n",
    "    # plot each author as a separate series\n",
    "    for auth in sorted(set(a)):\n",
    "        ax.plot(x[a==auth], y[a==auth], marker='o', linestyle='', label=auth)    \n",
    "        ax.legend(loc=\"upper left\", bbox_to_anchor=(1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<h4>You try it</h4>\n",
    "<p>ü§î Run the code and look at the results.</p>\n",
    "<p>ü§î Try adjusting the number of words considered (line 5: `nwords = 500`) and re-running it.</p>\n",
    "<p>Then proceed to the analysis below (if there's time).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<h5>‚úèÔ∏è Analysis</h5>\n",
    "<ul>\n",
    "<li>What do you notice in the graphs?</li>\n",
    "<li>Any final thoughts on this lab?</li>\n",
    "</ul>\n",
    "<p>Record your reflections in the cell below.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
